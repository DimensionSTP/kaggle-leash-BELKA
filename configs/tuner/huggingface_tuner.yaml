_target_: src.tuners.huggingface_tuner.HuggingFaceTuner
hparams:
  pretrained_model_name:
    - DeepChem/ChemBERTa-5M-MTR
    - DeepChem/ChemBERTa-10M-MTR
    - DeepChem/ChemBERTa-77M-MTR
  lr:
    low: 0.000005
    high: 0.00005
    log: False
  weight_decay:
    low: 0.001
    high: 0.01
    log: False
  period:
    low: 1
    high: 10
    log: False
  eta_min:
    low: 0.0000001
    high: 0.0000005
    log: False

module_params:
  num_labels: ${num_labels}
  average: macro
  interval: step
  devices: ${devices}
  accelerator: ${accelerator}
  strategy: ${strategy}
  log_every_n_steps: ${log_every_n_steps}
  precision: ${precision}
  accumulate_grad_batches: ${accumulate_grad_batches}
  gradient_clip_val: ${gradient_clip_val}
  gradient_clip_algorithm: ${gradient_clip_algorithm}
  max_epochs: ${epoch}
  monitor: ${monitor}
  mode: ${tracking_direction}
  patience: ${patience}
  min_delta: ${min_delta}

direction: maximize
seed: ${seed}
num_trials: ${num_trials}
hparams_save_path: ${hparams_save_path}